\documentclass[10pt]{article}

\title{Data Science 210 Final Project}
\author{Thomas Kwashnak}
\date{Fall 2021}
\usepackage{amsmath}
\usepackage{soul}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}
\usepackage{float}


\begin{document}
\maketitle
\setlength{\parindent}{0pt}.
\setlength{\parskip}{\baselineskip}
\lstset{numbers=left, numberstyle=\footnotesize, frame=l} 
\RestyleAlgo{ruled}

\tableofcontents
\newpage

% These sections are good for a start, however change them up as needed
\section{Background}
\subsection{Goals}
The main goal of this project is to create an algorithm that will be able to predict whether or not a player will win, from a given position on a Connect-4 board. To create an algorithm that does this, I used a neural network structure, which I trained specifically to do this calculation. To train the neural network, I used Stochastic Steepest Descent, and Back-Propagation as algorithms in order to "train" the network into accurately predicting if player 1 will win.
\subsection{Mathematics Overview}
The process for modifying the weights goes as follows. First, we use the neural network to take a set of inputs and get the output. We then compare that to the expected value using a loss function. Using that loss function, we find the derivative of the loss function in relation to each individual weight. Since we want to minimize the loss function, we take the derivative of each weight, which points towards the direction of greatest ascent, and go in the opposite direction by some step size. We repeat this whole process with different data entries, gradually reducing the step size, approaching a point where the network can generally predict the correct value.\newline
In order to make the forward propagation, or calculating the output of a neural network from a given input, we placed the weights in matricies. The inputs are put in a vector, and the weights in a matrix. Each row of the weight matrix represents a node in that network layer, and each column represent the weight associated with one of the input variables.
For example, an example of a 2-layer network, that only contains an input and an output layer, is represented as follows:
$$\begin{bmatrix} 1 & 2 \\ 2 & 1\end{bmatrix}\begin{pmatrix}1\\4\end{pmatrix} = \begin{pmatrix}9 \\ 6\end{pmatrix}$$
Where the first value is the weights, the second value is the input vector, and the last value is the output vector. When there are multiple layers, these are just recursively chained onto eachother. Each step of the way they are also normalized using a sigma function, which is described later in the design process.
\subsection{Dataset}


\section{Design}
During this section, a variety of variables and variable syntax will be used. The following is a list that explains each variable. Remember that for a given "layer", the output is considered the 0th layer, the hidden layer is considered the 1st layer, and the input is considered the 2nd layer.
\begin{description}[style=nextline]
    \item[$y^n$] The output vector of the nodes in the $n^{\text{th}}$ hidden layer. 
    \item[$y^n_{i,0}$] The output value of node $i$ in the $n^{\text{th}}$ hidden layer.
    \item[$y$] By default, if y is left alone, it represents the output value, known as $y^0_{0,0}$ 
    \item[$\hat{y}$] The expected final output as a scalar value
    \item[$W^n$] The weight matrix for a given layer $n$, as it applies to the values $Y^{n+1}$ (the outputs of the previous layer) 
    \item[$w^n_{i,j}$] The weight value for the value passed from node $j$ of layer $n+1$ as it is passed to node $i$ of layer $n$
\end{description}

I've sectioned off the design of the algorithms into the independant algorithms, ordering them to try and explain the progression of deriving the algorithms. 
This will take some experimentation, but the first idea is to 
\subsection{Sigmoid Activation Function}
In neural networks, an activation function is typically used to to condense the output of a node down to a [0-1] scale. In this lab, I used a sigmoid function. Below is the sigmoid function and it's derivative.
$$\sigma(n) = \frac{1}{1 + e^{-n}}$$
$$\sigma'(n) = \sigma(n) \cdot (1 - \sigma(n))$$

I used the following algorithm so that if I passed in a matrix, it would just apply the sigmoid function to each value in the matrix.

\begin{algorithm}[H]
    \caption{$\sigma(n)$ function for both constants and matrices}
    \KwIn{$A$ - which can either be a constant, or a $n$ x $m$ matrix}
    \KwOut{$B$ - which is equivilant to $\sigma(A)$}
    \uIf{$A$ is a Matrix}{
        $B \gets $new Matrix($n$ x $m$) of 0s\\
        \For{$i = 0, 1, 2... n$}{
            \For{$j = 0, 1, 2... m$}{
                $B[i][j] \gets \sigma(A[i,j])$
            }
        }
        \Return{$B$}
    }
    \Else{
        \Return{$1 / (1 + e^{-A})$}
    }
\end{algorithm}

\subsection{Feed-Forward Algorithm}
The Feed-Forward algorithm is the algorithm used to "run" a neural network. This is one of the fundamental steps in how a neural network works. This step is used whenever you want to find the output that a neural network will calculate from a given set of inputs. Since the neural network is siplit into 3 layers, the transition of the values from one layer to the next can be described as:
$$\vec{y^n} = \sigma(W_{n} \cdot \vec{y^{n+1}})$$
If we substitute in all of our layers, we can get the following equation as the result of the entire network.
$$y = y^0_{0,0} = \sigma(W_0 \cdot \sigma(W_1 \cdot \vec{y^2}))_{0,0}$$
\subsection{Loss Function}
In order to use gradient descent, we will need to create a function that measures the correctness of our network. This is known as the "Loss Function". The premise of the loss function is that the higher it is, the worse the network is. Therefore, in order to make our network more accurate, we need to minimize this value.
$$L = (y^0_0 - \hat{y})^2 = (y - \hat{y})^2$$

\subsection{$0^{\text{th}}$ Layer Weight Derivative}
In back propagation, we need to find the derivative of each of the weights in terms of the loss function. First, we need to find the derivative of the loss function with respect to the weights that connect the hidden layer with the output layer.\\
Given the following equations:

$$y^1_{i,0} = \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}})$$
$$y^0_{0,0} = \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})$$
We can calculate the derivative as follows:
$$\frac{\delta L}{\delta w^0_{0,i}} = \frac{\delta L}{\delta y^0_{0,0}} \cdot \frac{\delta y^0_{0,0}}{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}} \cdot \frac{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}}{\delta w^0_{0,i}}$$
$$\frac{\delta L}{\delta w^0_{0,i}} = 2 \cdot (y^0_{0,0} - \hat{y}) \cdot \sigma'(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot y^1_{i,0}$$
$$\frac{\delta L}{\delta w^0_{0,i}} = 2 \cdot (y^0_{0,0} - \hat{y}) \cdot \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot (1 - \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})) \cdot y^1_{i,0}$$
$$\frac{\delta L}{\delta w^0_{0,i}} = 2\cdot (y^0_{0,0} - \hat{y}) \cdot y^0_{0,0} \cdot (1 - y^0_{0,0}) \cdot y^1_{i,0}$$

\subsection{$1^{\text{st}}$ Layer Weight Derivative}
Next, we need to find the derivative of each of the weights that connect the input layer to the hidden layer.\\
Given the following equations:
$$y^1_{i,0} = \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}})$$
$$y^0_{0,0} = \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})$$
We can calculate the derivative as the following:
$$\frac{\delta L}{\delta w^1_{i,j}} = \frac{\delta L}{\delta y^0_{0,0}} \cdot \frac{\delta y^0_{0,0}}{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}} \cdot \frac{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}}{\delta y^1_{i,0}} \cdot \frac{\delta y^1_{i,0}}{\delta \sum_h{w^1_{i,h} \cdot y^2_h}} \cdot \frac{\delta \sum_h{w^1_{i,h} \cdot y^2_{h,0}}}{\delta w^1_{i,j}}$$
$$\frac{\delta L}{\delta w^1_{i,j}} = 2\cdot (y^0_{0,0} - \hat{y}) \cdot \sigma'(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot w^0_{0,i} \cdot \sigma'(\sum_h{w^1_{i,h} \cdot y^2_{h,0}}) \cdot y^2_{j,0}$$
$$\frac{\delta L}{\delta w^1_{i,j}} = 2 \cdot (y^0_{0,0} - \hat{y}) \cdot \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot (1 - \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})) \cdot w^0_{0,i} \cdot \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}}) \cdot (1 - \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}})) \cdot  y^2_{j,0}$$
$$\frac{\delta L}{\delta w^1_{i,j}} = 2 \cdot (y^0_{0,0} - \hat{y}) \cdot y^0_{0,0} \cdot (1 - y^0_{0,0}) \cdot w^0_{0,i} \cdot y^1_{i,0} \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0}$$
We can then reorder it as..
$$\frac{\delta L}{\delta w^1_{i,j}} = 2 \cdot (y^0_{0,0} - \hat{y}) \cdot y^0_{0,0} \cdot (1 - y^0_{0,0})\cdot y^1_{i,0} \cdot w^0_{0,i}  \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0}$$
And substitute in the $0^{\text{th}}$ layer derivative!
$$\frac{\delta L}{\delta w^1_{i,j}} = \frac{\delta L}{\delta w^0_{0,i}} \cdot w^0_{0,i}  \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0} $$

\subsection{Backward Propagation}
Backward Propagation is the whole accumilation of the previous algorithms to train a neural network. First, the Backward Propagation algorithm calculates the results of the network. After doing so, it calculates the partial derivatives of the loss function in relation to each of the weights (using the Layer Weight Derivatives above). Using these derivatives, it nudges the weights according to the Step coefficient to bring the network closer to the proper variable.\newline
Additionally, we will also calculate the absolute error of the propagation, which will make more sense in training the network\newline
\begin{algorithm}[H]
    \caption{Backward Propagation for a 2-layer neural network}
    \KwIn{
        $Y^2$ - The input vector (matrix), dimensions $m$ x $1$.\newline
        $W^1_\text{in}$ - The weight matrix, dimensions $h$ x $m$, that represents the weights used as variables go from $Y^2 \rightarrow Y^0$\newline
        $W^0_\text{in}$ - The weight matrix, dimensions $1$ x $h$, that represents the weights used as variables go from $Y^1 \rightarrow Y^0$\newline
        $S$ - The step coefficient to modify weights by, as a scalar value.\newline
        $\hat{y}$ - The expected result from Forward-Feeding
    }
    \KwOut{
        $W^1$ - The modified weight matrix, describing the same thing as $W^1_\text{in}$\newline
        $W^0$ - The modified weight matrix, describing the same thing as $W^0_\text{in}$\newline
        Err - The absolute error of the network
    }
    $W^1 \gets \text{copy of } W^1_\text{in}$\\
    $W^0 \gets \text{copy of } W^0_\text{in}$\\
    $Y^1 \gets \sigma(W^1 \cdot Y^2)$\\
    $Y^0 \gets \sigma(W^0 \cdot Y^1)$\\
    $\text{Err} \gets | (Y^0_{0,0} - \hat{y}) |$\\
    \For{$i \gets (0, 1, \ldots, h-1)$}{
        $\Delta W^0 \gets -S \cdot 2 \cdot (Y^0_{0,0} - \hat{y}) \cdot Y^0_{0,0} \cdot (1 - Y^0_{0,0}) \cdot Y^1_{i,0}$\\
        $W^0_{0,i} \gets W^0_{0,i} + \Delta W^0$\\
        \For{$j \gets (0, 1, \ldots, m-1)$}{
            $W^1_{i,j} \gets W^1_{i,j} + \Delta W^0 \cdot W^0_{0,i}  \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0}$
        }
    }
    \Return{$W^1, W^0$, Err}
\end{algorithm}

\subsection{Training the Network}
Now, if you give the same input and expected output into the Backwards Propagation enough times, it's going to give you a network wtih 0\% error for that input. However, it will perform very poorly when tested against a different set of inputs.\newline
While we do have an abundance of trials that we are able to draw from (67,557 entries to be exact), we could simply run through each and every entry multiple times to get enough data. The question relies in how we manage our Step value, which should be large at first, and as it progresses, gets smaller and smaller. The way that the network is trained will be up to a bit of experimentation, which I will be experimenting with.

% Pseudocode, referenced previous algorithms (just include their pseudocode)
\section{Implementation}
\subsection{Data Importing}
Since the data was given in a string csv format, an additional python script was created to import the data into two matricies, one contianing the inputs and one contianing the expected outputs.
% Reference methods / describe code?
\section{Validation}
\section{Reflection}
\end{document}