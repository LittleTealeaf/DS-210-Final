\documentclass[10pt]{article}

\title{Data Science 210 Final Project}
\author{Thomas Kwashnak}
\date{Fall 2021}
\usepackage{amsmath}
\usepackage{soul}
\usepackage{hyperref}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}
\usepackage{float}
\usepackage{url}


\begin{document}
\maketitle
\setlength{\parindent}{0pt}.
\setlength{\parskip}{\baselineskip}
\lstset{numbers=left, numberstyle=\footnotesize, frame=l} 
\RestyleAlgo{ruled}

\tableofcontents
\newpage

% These sections are good for a start, however change them up as needed
\section{Background}
\subsection{Goals}
The main goal of this project is to create an algorithm that will predict whether or not a given player is considered winning in any given state of connect-4. To do this, I created a neural network that takes in a connect-4 board state (6 wide x 7 high), and outputs a single number between $[0,1]$ that represents the predicted confidence that player 1 is winning. To train the network, I will use a stochastic gradient descent algorithm, as well as a back propagation algorithm, in order to update the weights.
\subsection{Mathematic Background}
The process of modifying the weights is what drives the neural network to learn. Training it is an iterative process; Each iteration, we give the network a random sample of data to train off of. We then take the average "gradient" and modify the weights accordingly.\par
To describe it best, lets start from the ground up. First, we are given a neural network. A neural network is a "network" that partially mimics a neuron map. The network is divided into layers. For this project, we will use a neural network with 1 hidden layer. If you are confused about how a neural network actually functions, I suggest watching this video (\url{https://www.youtube.com/watch?v=aircAruvnKk}) by 3blue1brown on Youtube. He does a great job with providing a clean animation to describe what is actually happening.\par
So we have a neural network, which basically is just a great big equation with a bunch of variables. Those variables, apart from the input variables, are all of our "weights". We store these weights into matrices. Each matrix represents the flow of values from one layer to the next\par
Now, we need to create a function we want to reduce, or a "loss" function. What this means is that the loss function should be lower if our network results in an answer closer to the expected answer for that input. In short, the higher the loss value, the worse the network. In order to improve the network, we need to modify the weights in such a way that it reduces the loss function.\par
This is where derivatives come in. Given a partial derivative of a function with respect to a variable, that derivative indicates the direction of greatest ascent in the function. If we inverse it, however, we get the direction of greatest \textit{descent}. Using this, we can calculate the partial derivative of the loss function with respect to each weight, and use that to modify the weights in such a way that improves the accuracy of the network. Each iteration, we reduce the "scale" at which we modify these variables by. Think of this as playing golf on a huge space. You want to get "within a ballpark" on your first shot, then fine tune further shots until you make it in the hole.\par
Now, while modifying the values each iteration from a single input/output would work, it makes the network favor earlier passes much more than later passes. To eliviate this, we keep the same network for a set of batch. We calculate the weight gradients for each input/output in the batch, and instead of applying each one to the network, we apply the average of the gradients to the network.\par
To summarize, we first iterate a number of times. Each iteration, we create a batch of randomly selected inputs and expected outputs. We feed those in, and use the loss function to find the partial derivatives for each of the weights. Next, we average out those derivatives for each weight, multiply it by some step factor that decreases over time, and apply those changes to the network. By repeating this, we start to get a network that can potentially properly evaluate our connect-4 state.

\subsection{Dataset}

In order to train the network to evaluate a state of a connect-4 game, I used a dataset of connect-4 games, which provided a list of connect-4 game states, and the resulting value of the game.
\begin{quote}
    John Tromp. (1995). Connect-4 \url{https://archive.ics.uci.edu/ml/datasets/Connect-4}. Irvine, CA: University of California, School of Information and Computer Science.
\end{quote}
The dataset contains 67,557 entries, each one representing a state in a game of Connect-4. As decribed on the database page:
\begin{quote}
    This database contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.\\
x is the first player; o the second.\\
The outcome class is the game theoretical value for the first player.
\end{quote}
The data is stored in a .csv file. Each row of the dataset represents a legal position. Each row is composed of 43 comma separated variables. The first 42 variables represent the board state, and the last one represents the expected value of whether player 1 wins, loses or draws.\par
For the board position, there are three possible states. 'x' means that the first player has placed a piece in that square. 'o' indicates that the second player has placed their piece in that square. 'b' indicates that the square is vacant.\par
There are three possible "results" of the board state. "win" means that player 1 is expected to win from this game state. "lose" means that player 2 is expected to win from this game state. "draw" means that neither player is expected to win, or that the board will be completely filled before any player can get 4 in a row.\par
In using the dataset, we need to convert the letters to numbers. First, for the board position, we will make $\text{'x'} = 1$, $\text{'o'} = -1$, and $\text{'b'} = 0$. Secondly, because we want our network to predict whether or not player 1 will win, we will make $\text{'lose'} = \text{'draw'} = 0$ and $\text{'win'} = 1$



\section{Design}
During this section, a variety of variables and variable syntax will be used. The following is a list that explains each variable. Remember that for a given "layer", the output is considered the 0th layer, the hidden layer is considered the 1st layer, and the input is considered the 2nd layer.
\begin{description}[style=nextline]
    \item[$y^n$] The output vector of the nodes in the $n^{\text{th}}$ hidden layer. 
    \item[$y^n_{i,0}$] The output value of node $i$ in the $n^{\text{th}}$ hidden layer.
    \item[$y$] By default, if y is left alone, it represents the output value, known as $y^0_{0,0}$ 
    \item[$\hat{y}$] The expected final output as a scalar value
    \item[$W^n$] The weight matrix for a given layer $n$, as it applies to the values $Y^{n+1}$ (the outputs of the previous layer) 
    \item[$w^n_{i,j}$] The weight value for the value passed from node $j$ of layer $n+1$ as it is passed to node $i$ of layer $n$
    \item[$\eta$] The step size of the gradient descent as it nudges the weights. 
\end{description}

I've sectioned off the design of the algorithms into the independant algorithms, ordering them to try and explain the progression of deriving the algorithms. 
This will take some experimentation, but the first idea is to 
\subsection{Sigmoid Activation Function}
In neural networks, an activation function is typically used to to condense the output of a node down to a [0-1] scale. In this lab, I used a sigmoid function. Below is the sigmoid function and it's derivative.
$$\sigma(n) = \frac{1}{1 + e^{-n}}$$
$$\sigma'(n) = \sigma(n) \cdot (1 - \sigma(n))$$

I used the following algorithm so that if I passed in a matrix, it would just apply the sigmoid function to each value in the matrix.

\begin{algorithm}[H]
    \caption{$\sigma(n)$ function for both constants and matrices}
    \KwIn{$A$ - which can either be a constant, or an array, with the first dimension being length $n$}
    \KwOut{$\sigma(A)$ - The result of putting $A$ through the $\sigma()$ function}
    \uIf{$A$ is a Matrix (or array)}{
        $B \gets $new Matrix of 0s in the same shape as $A$\\
        \For{$i = 0, 1, 2... n$}{
            \tcp{This works recursively until it reaches scalar values}
            $B[i] \gets \sigma(A[i])$
        }
        \Return{$B$}
    }
    \Else{
        \Return{$1 / (1 + e^{-A})$}
    }
\end{algorithm}

\subsection{Feed-Forward Algorithm}
The Feed-Forward algorithm is the algorithm used to "run" a neural network. This is one of the fundamental steps in how a neural network works. This step is used whenever you want to find the output that a neural network will calculate from a given set of inputs. Since the neural network is siplit into 3 layers, the transition of the values from one layer to the next can be described as:
$$\vec{y^n} = \sigma(W_{n} \cdot \vec{y^{n+1}})$$
If we substitute in all of our layers, we can get the following equation as the result of the entire network.
$$y = y^0_{0,0} = \sigma(W_0 \cdot \sigma(W_1 \cdot \vec{y^2}))_{0,0}$$
\subsection{Loss Function}
In order to use gradient descent, we will need to create a function that measures the correctness of our network. This is known as the "Loss Function". The premise of the loss function is that the higher it is, the worse the network is. Therefore, in order to make our network more accurate, we need to minimize this value.
$$L = (\hat{y} - y^0_{0,0})^2 = (]\hat{y} - y)^2$$

\subsection{0th Layer Weight Derivative}

In back propagation, we need to find the derivative of each of the weights in terms of the loss function. First, we need to find the derivative of the loss function with respect to the weights that connect the hidden layer with the output layer.\\
Given the following equations:

$$y^1_{i,0} = \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}})$$
$$y^0_{0,0} = \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})$$
We can calculate the derivative as follows:
$$\frac{\delta L}{\delta w^0_{0,i}} = \frac{\delta L}{\delta y^0_{0,0}} \cdot \frac{\delta y^0_{0,0}}{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}} \cdot \frac{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}}{\delta w^0_{0,i}}$$
$$\frac{\delta L}{\delta w^0_{0,i}} = 2 \cdot (\hat{y} - y^0_{0,0}) \cdot \sigma'(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot y^1_{i,0}$$
$$\frac{\delta L}{\delta w^0_{0,i}} = 2 \cdot (\hat{y} - y^0_{0,0}) \cdot \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot (1 - \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})) \cdot y^1_{i,0}$$
$$\frac{\delta L}{\delta w^0_{0,i}} = 2\cdot (\hat{y} - y^0_{0,0}) \cdot y^0_{0,0} \cdot (1 - y^0_{0,0}) \cdot y^1_{i,0}$$

\subsection{1st Layer Weight Derivative}
Next, we need to find the derivative of each of the weights that connect the input layer to the hidden layer.\\
Given the following equations:
$$y^1_{i,0} = \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}})$$
$$y^0_{0,0} = \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})$$
We can calculate the derivative as the following:
$$\frac{\delta L}{\delta w^1_{i,j}} = \frac{\delta L}{\delta y^0_{0,0}} \cdot \frac{\delta y^0_{0,0}}{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}} \cdot \frac{\delta \sum_h{w^0_{0,h} \cdot y^1_{h,0}}}{\delta y^1_{i,0}} \cdot \frac{\delta y^1_{i,0}}{\delta \sum_h{w^1_{i,h} \cdot y^2_h}} \cdot \frac{\delta \sum_h{w^1_{i,h} \cdot y^2_{h,0}}}{\delta w^1_{i,j}}$$
$$\frac{\delta L}{\delta w^1_{i,j}} = 2\cdot (\hat{y} - y^0_{0,0}) \cdot \sigma'(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot w^0_{0,i} \cdot \sigma'(\sum_h{w^1_{i,h} \cdot y^2_{h,0}}) \cdot y^2_{j,0}$$
$$\frac{\delta L}{\delta w^1_{i,j}} = 2 \cdot (\hat{y} - y^0_{0,0}) \cdot \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}}) \cdot (1 - \sigma(\sum_h{w^0_{0,h} \cdot y^1_{h,0}})) \cdot w^0_{0,i} \cdot \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}}) \cdot (1 - \sigma(\sum_h{w^1_{i,h} \cdot y^2_{h,0}})) \cdot  y^2_{j,0}$$
$$\frac{\delta L}{\delta w^1_{i,j}} = 2 \cdot (\hat{y} - y^0_{0,0}) \cdot y^0_{0,0} \cdot (1 - y^0_{0,0}) \cdot w^0_{0,i} \cdot y^1_{i,0} \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0}$$
We can then reorder it as..
$$\frac{\delta L}{\delta w^1_{i,j}} = 2 \cdot (\hat{y} - y^0_{0,0}) \cdot y^0_{0,0} \cdot (1 - y^0_{0,0})\cdot y^1_{i,0} \cdot w^0_{0,i}  \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0}$$
And substitute in the $0^{\text{th}}$ layer derivative!
$$\frac{\delta L}{\delta w^1_{i,j}} = \frac{\delta L}{\delta w^0_{0,i}} \cdot w^0_{0,i}  \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0} $$

\subsection{Backwards Propagation}
Backwards propagation is calculating the "gradient" of weights for a given input. I say "gradient" because in reality, the outputs of this algorithm will be two matricies, which each contain the derivative for each variable. We will be able to use these nudges in order to reduce the overall loss function. I also included an error calculations, such that we can also keep track of how accurate the network is at each batch of inputs.\newline
\begin{algorithm}[H]
    \caption{Back Propagation for a 2-layer neural network}
    \KwIn{
        $Y^2$ - The input vector (matrix), dimensions $m$ x $1$.\newline
        $W^1$ - The weight matrix, dimensions $h$ x $m$, that represents the weights used as variables go from $Y^2 \rightarrow Y^0$\newline
        $W^0$ - The weight matrix, dimensions $1$ x $h$, that represents the weights used as variables go from $Y^1 \rightarrow Y^0$\newline
        $\hat{y}$ - The expected result from Forward-Feeding
    }
    \KwOut{
        $\delta W^1$ - A matrix of the derivatives of the weights in $W^1$, as a $n$ x $m$ matrix.\newline
        $\delta W^0$ - A matrix of the derivatives of the weights in $W^0$, as a $1$ x $h$ matrix.\newline
        Err - The absolute error of the network for this given input
    }
    $\delta W^1 \gets$ new matrix of dimensions $n$ x $m$\\
    $\delta W^0 \gets$ new matrix of dimensions $1$ x $h$\\
    $Y^1 \gets \sigma(W^1 \cdot Y^2)$\\
    $Y^0 \gets \sigma(W^0 \cdot Y^1)$\\
    $\text{Err} \gets | \hat{y} - y^0_{0,0} |$\\
    \For{$i \gets (0, 1, \ldots, h-1)$}{
        $\delta W^0_{0,i} \gets 2 \cdot (\hat{y} - y^0_{0,0}) \cdot Y^0_{0,0} \cdot (1 - Y^0_{0,0}) \cdot Y^1_{i,0}$\\

        \For{$j \gets (0, 1, \ldots, m-1)$}{
            $\delta W^1_{i,j} \gets \delta W^0_{0,i} \cdot W^0_{0,i}  \cdot (1 - y^1_{i,0}) \cdot y^2_{j,0}$
        }
    }
    \Return{$\delta W^1, \delta W^0,$ Err}
\end{algorithm}

\subsection{Stochastic Gradient Descent}
For a good portion while working on this project, this was the part I was the most confused on. Stochastic steepest descent, at least my interpretation of it, is taking the accumulation of all of the weight changes taken from the back propagation algorithm, and averaging them before applying them to the network. The general formula is described as follows:
$$W^i = W^i  - \frac{\eta}{n} \cdot \sum_i^n{\text{Back-Propagation}(\ldots)_{W^i}} $$
To update each of the weights, we take the average changes in the back propagation, and multiply it by a scalar coefficient $\eta$, which represents the step size of the learning. The smaller $\eta$ is, the less the network will learn. For a single cycle in gradient descent, we will use the following algorithm to update the weights accordingly:\newline
\begin{algorithm}[H]
    \caption{Stochastic Gradient Descent Iteration}
    \KwIn{
        input - Length-$n$ list of input vectors, as matrices. Each input vector is of size $m$ x $1$\newline
        output - Length-$n$ list of all expected values, as scalars. Each output corresponds to the input at that same index\newline
        $W^1$ - The weight matrix, dimensions $h$ x $m$, that represents the weights used as variables go from $Y^2 \rightarrow Y^0$\newline
        $W^0$ - The weight matrix, dimensions $1$ x $h$, that represents the weights used as variables go from $Y^1 \rightarrow Y^0$\newline
        $\eta$ - The step coefficient to nudge the weights by.
    }
    \KwOut{
        $W^1$ - The updated weight matrix, dimensions $h$ x $m$, where values have been modified by their average derivative across all inputs/outputs, scaled by $\eta$\newline
        $W^0$ - The updated weight matrix, dimensions $1$ x $h$, where values have been modified by their average derivative across all inputs/outputs, scaled by $\eta$\newline
        Err - The average absolute error of the network on each input.
    }
    Err Total $\gets 0$\\
    $\Delta W^1 \gets$ matrix of zeros with dimensions $h$ x $m$\\
    $\Delta W^0 \gets$ matrix of zeros with dimensions $1$ x $h$\\
    \For{$i \gets 0, 1, \ldots, n-1$}{
        $\delta W^1, \delta W^0, \delta \text{Err} \gets $ Back Propagation on input$[i]$ and output$[i]$\\
        $\Delta W^1 \gets \Delta W^1 + \delta W^1$\\
        $\Delta W^0 \gets \Delta W^0 + \delta W^0$\\
        Err Total $\gets \text{Err Total} + \text{Err}$
    }
    Err Total $\gets \text{Err Total} / n$\\
    $W^1 \gets W^1 -  \eta / n \cdot \Delta W^1$\\
    $W^0 \gets W^0 - \eta / n \cdot \Delta W^0$\\
    \Return{$W^1, W^0, \text{Err Total}$}
\end{algorithm}

\subsection{Training the Network}
Now, in order to train the network, I need to send in batches of data for it to train on, and each batch of data I need to reduce the step function so the network can fine-tune its training. I plan to do this by using a random sample approach. I'll have a set of modifyable parameters, namely the batch size and the iteration count. These will allow me to change how many data points are put in to the network for each iteration, and how many iterations I will have. For step size, I will pass in a function, such that I can experiment with different step size functions. During implementation, I may also allow the ability to allow for keyboard interruption instead, so I can leave it running for however long I want, and come back to a trained network. The algorithm to perform this training is described as follows:\newline
\begin{algorithm}[H]
    \caption{Neural Network Training Algorithm}
    \KwIn{
        input - Length-$k$ list of input vectors, as matrices. Each input vector is of size $m$ x $1$\newline
        output - Length-$k$ list of all expected values, as scalars. Each output corresponds to the input at that same index\newline
        $W^1$ - The weight matrix, dimensions $h$ x $m$, that represents the weights used as variables go from $Y^2 \rightarrow Y^0$\newline
        $W^0$ - The weight matrix, dimensions $h$ x $m$, that represents the weights used as variables go from $Y^2 \rightarrow Y^0$\newline
        $f(i, I)$ - Step size function, which when passed in a current iteration $i$, and total iteration count $I$, returns the step size for that iteration\newline
        $n$ - The total number of iterations to run\newline
        $c$ - The total number of inputs to feed into each iteration\newline
        $seed$ - the random seed to use in the random selection of inputs
    }
    \KwOut{
        $W^1$ - The updated weight matrix, dimensions $h$ x $m$, trained on the given inputs and outputs
        $W^0$ - The updated weight matrix, dimensions $1$ x $h$, trained on the given inputs and outputs
    }
    \tcp{Set the random seed to seed here}
    \For{$i \gets 0, 1, \ldots, n-1$}{
        $\eta \gets f(i,I)$\\
        indexes $\gets$ list of uniform-random indexes within the range $[0,n-1]$ using the seed $seed$\\
        input-iteration $\gets$ list of inputs at each corresponding index from indexes\\
        output-iteration $\gets$ list of outputs at each corresponding index from indexes\\
        $W^1, W^0, Err \gets$ Stochastic Gradient Descent of weights and step size for input-iteration and output-iteration\\
        Log the $Err$ of the training
    }
    \Return{$W^1, W^0$}
\end{algorithm}
\section{Implementation}
\subsection{Data Importing}
Since the data was given in a .csv file type, with strings instead of numbers, another python script was created in order to convert the data into something the network could use. The file \path{data_import.py} contains the code responsbile for importing the data for the 
% Reference methods / describe code?
\section{Validation}
\section{Reflection}
\end{document}